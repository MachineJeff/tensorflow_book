{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-t TACOTRON] [-m MELGAN] [-d DENOISE]\n",
      "                             [-s SPLIT_INFOS] [-o OUTPUT_DIR]\n",
      "                             [-p PARAM_DENOISE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1002/jupyter/kernel-c4dfb8e3-e64f-415a-b569-19128ef827d9.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "@Author: yichao.li\n",
    "@Date:   2020-04-27\n",
    "@Description: merge two pbs into one savedmodel\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "def denoiser(melgan_two_outputs, param_denoise):\n",
    "    with tf.variable_scope('denoiser'):\n",
    "        bias_audio = tf.identity(tf.squeeze(melgan_two_outputs[1], 1))\n",
    "        bias_audio = tf.expand_dims(bias_audio, 0)\n",
    "\n",
    "        real_audio = tf.identity(tf.squeeze(melgan_two_outputs[0],1))\n",
    "        real_audio = tf.expand_dims(real_audio, 0)\n",
    "\n",
    "        bias_spec = tf.abs(tf.contrib.signal.stft(bias_audio, 800, 200, 2048))\n",
    "\n",
    "        audio_stft = tf.contrib.signal.stft(real_audio, 800, 200, 2048)\n",
    "        audio_spec = tf.abs(audio_stft)\n",
    "        audio_angles = audio_stft / tf.cast(tf.maximum(1e-8, audio_spec), tf.complex64)\n",
    "\n",
    "        param = tf.constant([param_denoise], dtype=tf.float32) \n",
    "        audio_spec_denoised = tf.subtract(audio_spec, tf.multiply(bias_spec, param))\n",
    "        audio_spec_denoised = tf.clip_by_value(audio_spec_denoised, 0.0, 999999999.0)\n",
    "        S_complex = tf.cast(audio_spec_denoised, dtype=tf.complex64)\n",
    "\n",
    "        denoiser_audio = tf.contrib.signal.inverse_stft(S_complex * audio_angles, 800, 200, 2048)\n",
    "        return tf.squeeze(denoiser_audio, 0)\n",
    "\n",
    "def merge(args):\n",
    "    # load tacotron pb\n",
    "    tf.reset_default_graph()\n",
    "    graph_A = tf.GraphDef()\n",
    "    with tf.gfile.GFile(args.tacotron, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        graph_A.ParseFromString(serialized_graph)\n",
    "\n",
    "\n",
    "    # load melgan pb\n",
    "    tf.reset_default_graph()\n",
    "    graph_B = tf.GraphDef()\n",
    "    with tf.gfile.GFile(args.melgan, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        graph_B.ParseFromString(serialized_graph)\n",
    "\n",
    "    # some nodes in melgan is locked, you must free it at first\n",
    "    for node in graph_B.node:\n",
    "        if node.op == 'Assign':\n",
    "            node.op = 'Identity'\n",
    "        if 'use_locking' in node.attr: del node.attr['use_locking']\n",
    "        if 'validate_shape' in node.attr: del node.attr['validate_shape']\n",
    "        # if len(node.input) == 2:\n",
    "        #     # input0: ref: Should be from a Variable node. May be uninitialized.\n",
    "        #     # input1: value: The value to be assigned to the variable.\n",
    "        #     node.input[0] = node.input[1]\n",
    "        #     del node.input[1]\n",
    "\n",
    "    # merge two graphs into one\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Graph().as_default() as graphs_merged:\n",
    "        with tf.Session(graph=graphs_merged) as sess:\n",
    "            inputs = tf.placeholder(tf.int32, [1, None], name='inputs')\n",
    "            input_lengths = tf.placeholder(tf.int32, [1], name='input_lengths')\n",
    "            \n",
    "            if args.split_infos:\n",
    "                split_infos = tf.placeholder(tf.int32, shape=[1, None], name='split_infos')\n",
    "                mel_out, = tf.import_graph_def(\n",
    "                    graph_A, \n",
    "                    input_map={\"inputs:0\": inputs, \"input_lengths:0\": input_lengths, \"split_infos:0\": split_infos},\n",
    "                    return_elements=[\"Tacotron_model/inference/add:0\"], \n",
    "                    name=\"\")\n",
    "            else:\n",
    "                mel_out, = tf.import_graph_def(\n",
    "                    graph_A, \n",
    "                    input_map={\"inputs:0\": inputs, \"input_lengths:0\": input_lengths},\n",
    "                    return_elements=[\"Tacotron-2/inference/Minimum_1:0\"], \n",
    "                    name=\"\")\n",
    "\n",
    "            if args.denoise:\n",
    "                mel_out = tf.pad(mel_out,[[0,1],[0,0],[0,0]], mode=\"CONSTANT\", constant_values=0)\n",
    "\n",
    "            print(\"------successed done build input and melspec!-----\")\n",
    "\n",
    "            audio, = tf.import_graph_def(\n",
    "                graph_B, \n",
    "                input_map={\"mel_G:0\": mel_out},\n",
    "                return_elements=[\"MelGAN/Generator/Tanh:0\"], \n",
    "                name=\"\")\n",
    "\n",
    "            # make sure node is identity\n",
    "            tf.identity(audio, \"MelGAN/Generator/Tanh\")\n",
    "\n",
    "            print(\"------successed done build output audio!-----\")\n",
    "            \n",
    "\n",
    "            # export to saved model\n",
    "            if args.split_infos and args.denoise:\n",
    "                tf.saved_model.simple_save(\n",
    "                    sess,\n",
    "                    args.output_dir,\n",
    "                    inputs={\"input_lengths\": input_lengths,\"inputs\": inputs,\"split_infos\":split_infos},\n",
    "                    outputs={\"audio\": denoiser(tf.get_default_graph().get_tensor_by_name(\"MelGAN/Generator/Tanh:0\"), args.param_denoise)})\n",
    "            elif args.split_infos and not args.denoise:\n",
    "                tf.saved_model.simple_save(\n",
    "                    sess,\n",
    "                    args.output_dir,\n",
    "                    inputs={\"input_lengths\": input_lengths,\"inputs\": inputs,\"split_infos\":split_infos},\n",
    "                    outputs={\"audio\": tf.get_default_graph().get_tensor_by_name(\"MelGAN/Generator/Tanh:0\")})\n",
    "            elif not args.split_infos and args.denoise:\n",
    "                tf.saved_model.simple_save(\n",
    "                    sess,\n",
    "                    args.output_dir,\n",
    "                    inputs={\"input_lengths\": input_lengths,\"inputs\": inputs},\n",
    "                    outputs={\"audio\": denoiser(tf.get_default_graph().get_tensor_by_name(\"MelGAN/Generator/Tanh:0\"), args.param_denoise)})\n",
    "            else:\n",
    "                tf.saved_model.simple_save(\n",
    "                    sess,\n",
    "                    args.output_dir,\n",
    "                    inputs={\"input_lengths\": input_lengths,\"inputs\": inputs},\n",
    "                    outputs={\"audio\": tf.get_default_graph().get_tensor_by_name(\"MelGAN/Generator/Tanh:0\")})\n",
    "\n",
    "            print(\"------your denoise is {}.------\".format(args.denoise))\n",
    "            print(\"------your split_infos is {}.------\".format(args.split_infos))\n",
    "            print(\"------successed merge graph to {} !------\".format(args.output_dir))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-t\",\n",
    "        \"--tacotron\",\n",
    "        type=str,\n",
    "        default='/home/yichao.li/pb/meltron/t2origin.pb')\n",
    "    parser.add_argument(\n",
    "        \"-m\",\n",
    "        \"--melgan\",\n",
    "        type=str,\n",
    "        default= '/home/yichao.li/pb/melgan/melgan.pb')\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--denoise\",\n",
    "        type=bool,\n",
    "        default=False)\n",
    "    parser.add_argument(\n",
    "        \"-s\",\n",
    "        \"--split_infos\",\n",
    "        type=bool,\n",
    "        default=False)\n",
    "    parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output_dir\",\n",
    "        type=str,\n",
    "        default='/home/yichao.li/pb/12')\n",
    "    parser.add_argument(\n",
    "        \"-p\",\n",
    "        \"--param_denoise\",\n",
    "        type=int,\n",
    "        default=3000)\n",
    "    args = parser.parse_args()\n",
    "    merge(args)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.12]",
   "language": "python",
   "name": "conda-env-tf1.12-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
